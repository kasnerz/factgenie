{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 0, "annotations": [{"reason": "The cast member mentioned in the text does not match the data", "text": "Friedensreich Hundertwasser", "type": 0, "start": 95}, {"reason": "The director mentioned in the text does not match the data", "text": "Peter Schamoni", "type": 0, "start": 66}, {"reason": "The filming location mentioned in the text does not match the data", "text": "Venice", "type": 0, "start": 142}, {"reason": "The original language mentioned in the text does not match the data", "text": "German", "type": 0, "start": 167}, {"reason": "The composer mentioned in the text does not match the data", "text": "Arik Brauer", "type": 0, "start": 191}, {"reason": "The director of photography mentioned in the text does not match the data", "text": "Josef Kaufmann", "type": 0, "start": 217}, {"reason": "The film editor mentioned in the text does not match the data", "text": "Heidi Gen\u00e9e", "type": 0, "start": 233}, {"reason": "The genre mentioned in the text does not match the data", "text": "documentary film", "type": 0, "start": 37}, {"reason": "The instance of mentioned in the text does not match the data", "text": "short documentary film", "type": 0, "start": 31}, {"reason": "The nomination mentioned in the text does not match the data", "text": "Academy Award for Best Documentary (Short Subject)", "type": 0, "start": 289}], "campaign_id": "quintd1-gpt-4", "batch_id": 0}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 1, "annotations": [{"reason": "The text states 'Catalan Republic' is a historical country, while the data mentions it as an instance of a historical country.", "text": "historical country", "type": 0, "start": 26}, {"reason": "The text states 'Catalan Republic' is a state with limited recognition, while the data does not mention it as a state with limited recognition.", "text": "state with limited recognition", "type": 0, "start": 118}, {"reason": "The text incorrectly states 'Catalan Republic' is 'a historical country', while the data does not mention it.", "text": "historical country", "type": 0, "start": 26}, {"reason": "The text suggests 'Catalan Republic' is a 'country', while the data mentions it as an instance of a state with limited recognition.", "text": "country", "type": 0, "start": 230}, {"reason": "The text states 'Catalan Republic' is situated in the '00' time zone, while the data does not mention it.", "text": "00", "type": 0, "start": 360}], "campaign_id": "quintd1-gpt-4", "batch_id": 1}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 2, "annotations": [{"reason": "The text states 'historical country', but the data does not mention the term 'country'", "text": "historical country", "type": 0, "start": 19}, {"reason": "The text mentions 'Central Provinces' while the data specifies 'the administrative territorial entity: Central Provinces'", "text": "Central Provinces", "type": 0, "start": 138}, {"reason": "The text refers to 'Brockhaus and Efron Encyclopedic Dictionary' as a source, but the data does not specifically mention 'source' as an attribute", "text": "Brockhaus and Efron Encyclopedic Dictionary", "type": 0, "start": 201}], "campaign_id": "quintd1-gpt-4", "batch_id": 2}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 3, "annotations": [{"reason": "The film is not rated by Medier\u00e5det for ages 15 and up", "text": "rated for ages 15 and up", "type": 0, "start": 28}, {"reason": "The film is based on the book 'Father of Frankenstein' not a book", "text": "\"Father of Frankenstein\"", "type": 0, "start": 92}, {"reason": "California is not the main narrative location of the film", "text": "narrative is set in California", "type": 0, "start": 347}, {"reason": "The film's main subject is not suicide", "text": "main subject of the film is suicide", "type": 0, "start": 306}], "campaign_id": "quintd1-gpt-4", "batch_id": 3}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 4, "annotations": [{"reason": "The text lists the country as Yugoslavia, while the data does not specify the country.", "text": "Yugoslavia", "type": 0, "start": 29}, {"reason": "The text does not provide the specific title of the film as 'Plavi 9', as mentioned in the data.", "text": "Plavi 9", "type": 0, "start": 0}], "campaign_id": "quintd1-gpt-4", "batch_id": 4}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 5, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "Chief Executive Officer", "type": 0, "start": 205}, {"reason": "The fact in the text contradicts the data", "text": "Southern Uzbek", "type": 0, "start": 295}, {"reason": "The fact in the text contradicts the data", "text": "contains the administrative territorial entities of Paktika and Nangarhar", "type": 0, "start": 337}], "campaign_id": "quintd1-gpt-4", "batch_id": 5}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 6, "annotations": [{"reason": "The text refers to 'monarchy form of government' whereas in the data, it is 'absolute monarchy'", "text": "monarchy form of government", "type": 0, "start": 97}, {"reason": "The text refers to 'continent of Asia' whereas in the data, it is 'Asia'", "text": "continent of Asia", "type": 0, "start": 190}, {"reason": "The text refers to 'significant topic' which is not present in the data", "text": "significant topic", "type": 1, "start": 230}, {"reason": "The text refers to 'categorized as a Chinese dynasty' whereas in the data, it is 'topic's main category: Qin dynasty'", "text": "categorized as a Chinese dynasty", "type": 0, "start": 278}], "campaign_id": "quintd1-gpt-4", "batch_id": 6}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 7, "annotations": [{"reason": "The airline is not mentioned in the data", "text": "Comores Aviation International", "type": 0, "start": 0}, {"reason": "The headquarters location is not mentioned in the data", "text": "based in Moroni", "type": 1, "start": 45}, {"reason": "The airline's operation out of a hub is not mentioned in the data", "text": "operates out of its hub at", "type": 1, "start": 83}, {"reason": "Not checkable in the data", "text": "a notable airline in the region", "type": 1, "start": 163}], "campaign_id": "quintd1-gpt-4", "batch_id": 7}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 8, "annotations": [{"reason": "The text mentions 'male', but the data doesn't mention 'male' or 'gender'.", "text": "male", "type": 0, "start": 23}, {"reason": "The text mentions 'small forward', but the data mentions 'small forward' as 'position played on team / speciality'.", "text": "small forward", "type": 1, "start": 87}], "campaign_id": "quintd1-gpt-4", "batch_id": 8}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 9, "annotations": [{"reason": "Not checkable", "text": "Gandhara", "type": 1, "start": 0}, {"reason": "Not checkable", "text": "historical country", "type": 1, "start": 15}, {"reason": "Not checkable", "text": "Asia", "type": 1, "start": 45}, {"reason": "Not checkable", "text": "described by sources such as Brockhaus and Efron Encyclopedic Dictionary and Paulys Realenzyklop\u00e4die der klassischen Altertumswissenschaft", "type": 1, "start": 54}, {"reason": "Incorrect fact", "text": "categorized as a topic under Gandhara", "type": 0, "start": 200}, {"reason": "Misleading", "text": "is known for its significance in ancient history", "type": 2, "start": 242}], "campaign_id": "quintd1-gpt-4", "batch_id": 9}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 10, "annotations": [{"reason": "Incorrect fact: The fact in the text contradicts the data.", "text": "based in", "type": 0, "start": 37}], "campaign_id": "quintd1-gpt-4", "batch_id": 10}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 11, "annotations": [{"reason": "Incorrect fact: The fact in the text contradicts the data.", "text": "male", "type": 0, "start": 26}, {"reason": "Misleading: The fact in the text is misleading in the given context.", "text": "He was born in", "type": 2, "start": 60}], "campaign_id": "quintd1-gpt-4", "batch_id": 11}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 12, "annotations": [{"reason": "In the text, the film is mentioned to have colorful cinematography which is not specified in the data", "text": "colorful cinematography", "type": 1, "start": 56}, {"reason": "The composer's full name 'Gangai Amaran' is not used as in the data", "text": "Gangai Amaran", "type": 0, "start": 202}, {"reason": "The director's name 'Prabhu Ganesan' is not specified in the data", "text": "Prabhu Ganesan", "type": 1, "start": 116}, {"reason": "The director's name 'Sivaji Ganesan' is not specified in the data", "text": "Sivaji Ganesan", "type": 1, "start": 135}], "campaign_id": "quintd1-gpt-4", "batch_id": 12}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 13, "annotations": [{"reason": "Incorrect fact: The headquarters location in the text is different from the data", "text": "Carlsbad, United States of America", "type": 0, "start": 66}, {"reason": "Misleading: The text suggests that the company specializes in biotechnology, which is not specifically mentioned in the data", "text": "biotechnology", "type": 2, "start": 130}], "campaign_id": "quintd1-gpt-4", "batch_id": 13}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 14, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "French film", "type": 0, "start": 212}, {"reason": "The fact in the text contradicts the data", "text": "featuring", "type": 0, "start": 42}], "campaign_id": "quintd1-gpt-4", "batch_id": 14}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 15, "annotations": [{"reason": "The text states that the film is in color, but the data does not specify the color type", "text": "color", "type": 0, "start": 21}], "campaign_id": "quintd1-gpt-4", "batch_id": 15}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 16, "annotations": [{"reason": "The sport mentioned is Gaelic football, while the data specifies 'Gaelic football player'", "text": "Gaelic football player", "type": 0, "start": 21}, {"reason": "The text is not related to the data and cannot be verified", "text": "is known for his contributions to the sport", "type": 1, "start": 119}, {"reason": "The given name mentioned in the text and the data match", "text": "Vincent", "type": 2, "start": 183}], "campaign_id": "quintd1-gpt-4", "batch_id": 16}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 17, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "It is a notable instance of Indian cinema", "type": 0, "start": 71}, {"reason": "The fact in the text contradicts the data", "text": "known for its thrilling and suspenseful genre", "type": 0, "start": 114}], "campaign_id": "quintd1-gpt-4", "batch_id": 17}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 18, "annotations": [{"reason": "Not checkable", "text": "business", "type": 1, "start": 14}], "campaign_id": "quintd1-gpt-4", "batch_id": 18}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 19, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "a historical country", "type": 2, "start": 24}, {"reason": "The fact in the text contradicts the data.", "text": "was governed as a monarchy", "type": 0, "start": 94}, {"reason": "The fact in the text contradicts the data.", "text": "The official language of the Beylik was Turkish", "type": 0, "start": 174}, {"reason": "The fact in the text contradicts the data.", "text": "The Beylik of Tunis is categorized as a historical country.", "type": 1, "start": 275}], "campaign_id": "quintd1-gpt-4", "batch_id": 19}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 20, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "female", "type": 0, "start": 25}, {"reason": "Not checkable", "text": "human", "type": 1, "start": 32}, {"reason": "Other", "text": "Her given name is Emma.", "type": 3, "start": 39}], "campaign_id": "quintd1-gpt-4", "batch_id": 20}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 21, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "high-quality", "type": 0, "start": 116}], "campaign_id": "quintd1-gpt-4", "batch_id": 21}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 22, "annotations": [{"reason": "The fact contradicts the data: the text mentions female gender, but the data specifies the gender as 'sex or gender: female'.", "text": "female", "type": 0, "start": 23}], "campaign_id": "quintd1-gpt-4", "batch_id": 22}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 23, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "ancient", "type": 0, "start": 35}, {"reason": "Not checkable", "text": "It is categorized under the main topic of the Fourth Dynasty of Egypt.", "type": 1, "start": 61}], "campaign_id": "quintd1-gpt-4", "batch_id": 23}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 24, "annotations": [{"reason": "Misleading: The film is not necessarily from the British Raj era", "text": "British Raj era", "type": 2, "start": 54}, {"reason": "Incorrect fact: Naresh Mitra is not listed as a director", "text": "Naresh Mitra", "type": 0, "start": 83}, {"reason": "Other: Unnecessary repetition of 'Sisir Bhaduri'", "text": "Sisir Bhaduri", "type": 3, "start": 100}, {"reason": "Incorrect fact: The film is not explicitly mentioned as silent in the data", "text": "silent", "type": 0, "start": 33}], "campaign_id": "quintd1-gpt-4", "batch_id": 24}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 25, "annotations": [{"reason": "The headquarters location in the text and data do not match", "text": "Gauting", "type": 0, "start": 16}], "campaign_id": "quintd1-gpt-4", "batch_id": 25}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 26, "annotations": [{"reason": "The text mentions 'parliament' without stating it's the parliament of Yugoslavia", "text": "parliament", "type": 0, "start": 248}, {"reason": "The text mentions 3 official languages while the data lists only 2", "text": "Slovene", "type": 0, "start": 313}, {"reason": "The text mentions 'flag of Yugoslavia' without specifying the name", "text": "flag of Yugoslavia", "type": 0, "start": 185}, {"reason": "The text mentions 'Serbo-Croatian' as an official language, which contradicts the data", "text": "Serbo-Croatian", "type": 0, "start": 297}], "campaign_id": "quintd1-gpt-4", "batch_id": 26}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 27, "annotations": [{"reason": "The text states that the film is called 'The Head of Gonzalez', while the data only mentions 'Gonzalez'", "text": "The Head of Gonzalez", "type": 0, "start": 0}, {"reason": "The text mentions the cast member as 'Fritz Greiner' instead of 'Fritz Greiner' as per the data", "text": "Fritz Greiner", "type": 0, "start": 106}], "campaign_id": "quintd1-gpt-4", "batch_id": 27}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 28, "annotations": [{"reason": "The text mentions 'Hawthorns Public House' instead of 'The Hawthorns Public House'", "text": "Hawthorns Public House", "type": 0, "start": 4}, {"reason": "The text does not mention that the 'Hawthorns Public House' is recognized as a pub", "text": "Grade II listed building", "type": 0, "start": 32}, {"reason": "The text mentions 'United Kingdom' before 'Sandwell' instead of after", "text": "United Kingdom", "type": 2, "start": 131}], "campaign_id": "quintd1-gpt-4", "batch_id": 28}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 29, "annotations": [{"reason": "The text mentions 'Ohana\u672c\u8217' as 'Ohana\u672c\u8217'", "text": "Ohana\u672c\u8217", "type": 0, "start": 0}, {"reason": "The text mentions \u014cita as '\u014cita'", "text": "\u014cita", "type": 0, "start": 39}], "campaign_id": "quintd1-gpt-4", "batch_id": 29}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 30, "annotations": [{"reason": "The text contradicts the data by stating that the Lithuanian Soviet Socialist Republic was considered a puppet state, while the data lists it as a puppet state", "text": "considered a puppet state", "type": 0, "start": 156}, {"reason": "The official language is stated as \"Russian\", while the data specifies the \"Russian language used\"", "text": "Russian", "type": 0, "start": 214}, {"reason": "The text is misleading as it implies that the anthem and coat of arms were specific to the Lithuanian Soviet Socialist Republic, while the data only specifies them as related to the republic", "text": "specific to the Lithuanian Soviet Socialist Republic", "type": 2, "start": 260}], "campaign_id": "quintd1-gpt-4", "batch_id": 30}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 31, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "Mahan confederacy", "type": 0, "start": 4}, {"reason": "The fact in the text contradicts the data", "text": "was a historical country", "type": 0, "start": 22}, {"reason": "The fact in the text contradicts the data", "text": "and a confederation", "type": 0, "start": 47}, {"reason": "The fact in the text contradicts the data", "text": "It consisted of two parts, Bulmiguk and Yeoraebiriguk", "type": 0, "start": 96}, {"reason": "The fact in the text contradicts the data", "text": "is categorized under the topic \"\ub9c8\ud55c\"", "type": 0, "start": 155}], "campaign_id": "quintd1-gpt-4", "batch_id": 31}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 32, "annotations": [{"reason": "The text contradicts the data, as it specifies the company as primarily involved in the production and distribution of pallets, crates, and wooden packaging, while the data doesn't specify the exact nature of the company's operations.", "text": "is primarily involved in the production and distribution of pallets, crates, and wooden packaging.", "type": 0, "start": 173}], "campaign_id": "quintd1-gpt-4", "batch_id": 32}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 33, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "realm", "type": 0, "start": 29}, {"reason": "The fact in the text contradicts the data", "text": "with its capital in Pamplona", "type": 0, "start": 82}, {"reason": "The fact in the text contradicts the data", "text": "includes", "type": 0, "start": 154}, {"reason": "The fact in the text contradicts the data", "text": "head of state", "type": 0, "start": 224}, {"reason": "The fact in the text contradicts the data", "text": "holds the office of Monarch of Pamplona", "type": 0, "start": 238}, {"reason": "The fact in the text contradicts the data", "text": "The official religion is the Catholic Church", "type": 0, "start": 283}], "campaign_id": "quintd1-gpt-4", "batch_id": 33}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 34, "annotations": [{"reason": "The text mentions the film as a silent film, but the data doesn't include this genre", "text": "silent", "type": 0, "start": 39}, {"reason": "The text suggests that the film is now in the public domain, but the data doesn't confirm this status", "text": "public domain", "type": 0, "start": 225}, {"reason": "The text states that the film is considered a lost film, but the data doesn't include this information", "text": "lost film", "type": 0, "start": 197}], "campaign_id": "quintd1-gpt-4", "batch_id": 34}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 35, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "Icelandic", "type": 0, "start": 26}, {"reason": "The fact in the text contradicts the data.", "text": "forward", "type": 0, "start": 88}, {"reason": "The fact in the text contradicts the data.", "text": "Valur", "type": 0, "start": 170}, {"reason": "The fact in the text contradicts the data.", "text": "IFK Norrk\u00f6ping", "type": 0, "start": 177}, {"reason": "The fact in the text contradicts the data.", "text": "SpVgg Unterhaching", "type": 0, "start": 193}, {"reason": "The fact in the text contradicts the data.", "text": "L.A.S.K. Linz", "type": 0, "start": 217}, {"reason": "The fact in the text contradicts the data.", "text": "Iceland national under-17, under-21, and senior football teams", "type": 0, "start": 305}], "campaign_id": "quintd1-gpt-4", "batch_id": 35}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 36, "annotations": [{"reason": "The text mentions 'color' while the correct term is 'in color'", "text": "color", "type": 0, "start": 107}, {"reason": "The text mentions 'filmed in Utah' while the correct term is 'filming location: Utah'", "text": "filmed in Utah", "type": 0, "start": 75}, {"reason": "The text mentions 'language' while the correct term is 'original language of film or TV show'", "text": "language", "type": 0, "start": 187}, {"reason": "The text mentions a 'cast member' while the correct term is 'cast member: Richard Dutcher'", "text": "cast member", "type": 0, "start": 224}], "campaign_id": "quintd1-gpt-4", "batch_id": 36}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 37, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "black-and-white", "type": 0, "start": 23}, {"reason": "The fact in the text contradicts the data", "text": "drama film", "type": 0, "start": 39}, {"reason": "The fact in the text contradicts the data", "text": "produced by Shint\u014dh\u014d", "type": 0, "start": 50}], "campaign_id": "quintd1-gpt-4", "batch_id": 37}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 38, "annotations": [], "campaign_id": "quintd1-gpt-4", "batch_id": 38}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 39, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "Baban", "type": 0, "start": 0}, {"reason": "The fact in the text contradicts the data", "text": "distinct from another entity also called Baban", "type": 0, "start": 40}], "campaign_id": "quintd1-gpt-4", "batch_id": 39}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 40, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "Utum", "type": 0, "start": 0}, {"reason": "The fact in the text contradicts the data.", "text": "was a historical country", "type": 0, "start": 5}, {"reason": "The fact in the text contradicts the data.", "text": "ancient history", "type": 0, "start": 33}, {"reason": "The fact in the text contradicts the data.", "text": "as described by the source Paulys Realenzyklop\u00e4die der klassischen Altertumswissenschaft", "type": 0, "start": 50}, {"reason": "The fact in the text contradicts the data.", "text": "It was located on the terrain feature known as Little Zab", "type": 0, "start": 140}], "campaign_id": "quintd1-gpt-4", "batch_id": 40}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 41, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "CBS Associated Records", "type": 0, "start": 0}, {"reason": "The fact in the text contradicts the data", "text": "CBS", "type": 0, "start": 100}, {"reason": "The fact in the text contradicts the data", "text": "CBS Records", "type": 0, "start": 108}, {"reason": "The fact in the text contradicts the data", "text": "CBS Associated Records catalog", "type": 0, "start": 161}], "campaign_id": "quintd1-gpt-4", "batch_id": 41}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 42, "annotations": [{"reason": "Incorrect fact: The text mentions 'business' but data doesn't include this", "text": "business", "type": 0, "start": 46}, {"reason": "Not checkable: The text includes a specific work 'Young Vic' which is not covered in the data", "text": "Young Vic", "type": 1, "start": 231}], "campaign_id": "quintd1-gpt-4", "batch_id": 42}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 43, "annotations": [{"reason": "Incorrect fact: The text states 'Argentine origin' while the data states 'country of origin: Argentina'", "text": "Argentine", "type": 0, "start": 36}, {"reason": "Incorrect fact: The text states 'color aesthetics' while the data states 'color: color'", "text": "color aesthetics", "type": 0, "start": 123}], "campaign_id": "quintd1-gpt-4", "batch_id": 43}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 44, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "located in the continent of Asia", "type": 0, "start": 78}, {"reason": "The fact in the text contradicts the data.", "text": "with its capital in Indore", "type": 0, "start": 112}, {"reason": "The fact in the text contradicts the data.", "text": "This information is described by both the Brockhaus and Efron Encyclopedic Dictionary and the Small Brockhaus and Efron Encyclopedic Dictionary.", "type": 0, "start": 140}], "campaign_id": "quintd1-gpt-4", "batch_id": 44}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 45, "annotations": [{"reason": "The text mentions 'male' while the data states 'sex or gender'", "text": "male", "type": 0, "start": 24}, {"reason": "The text mentions 'grass skiing competitor' while the data states 'occupation'", "text": "grass skiing competitor", "type": 0, "start": 82}], "campaign_id": "quintd1-gpt-4", "batch_id": 45}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 46, "annotations": [{"reason": "The text is more specific than the data (the heritage designation in the data is less specific)", "text": "NRHP contributing property", "type": 0, "start": 166}, {"reason": "The text is not specific", "text": "United States of America", "type": 1, "start": 95}], "campaign_id": "quintd1-gpt-4", "batch_id": 46}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 47, "annotations": [{"reason": "Not checkable", "text": "Sparkasse an der Lippe", "type": 1, "start": 0}, {"reason": "Not checkable", "text": "is a member of the Sparkassen-Finanzgruppe", "type": 1, "start": 146}, {"reason": "Misleading", "text": "provides various banking and financial services to its customers", "type": 2, "start": 258}], "campaign_id": "quintd1-gpt-4", "batch_id": 47}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 48, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "New York", "type": 0, "start": 59}, {"reason": "The fact in the text contradicts the data", "text": "United States of America", "type": 0, "start": 69}, {"reason": "The fact in the text contradicts the data", "text": "United States of America", "type": 0, "start": 266}], "campaign_id": "quintd1-gpt-4", "batch_id": 48}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 49, "annotations": [{"reason": "The fact contradicts the data: 'business' is not mentioned in the text", "text": "business", "type": 0, "start": 19}, {"reason": "The fact contradicts the data: 'operating within' is not equivalent to 'instance of'", "text": "operating within", "type": 0, "start": 67}], "campaign_id": "quintd1-gpt-4", "batch_id": 49}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 50, "annotations": [{"reason": "Not checkable", "text": "Chicago Cab", "type": 1, "start": 0}, {"reason": "Not checkable", "text": "featuring", "type": 1, "start": 44}, {"reason": "Incorrect fact", "text": "Tracy Letts", "type": 0, "start": 75}, {"reason": "Incorrect fact", "text": "Kevin J. O'Connor", "type": 0, "start": 88}, {"reason": "Incorrect fact", "text": "John Cusack", "type": 0, "start": 107}, {"reason": "Incorrect fact", "text": "Moira Harris", "type": 0, "start": 120}, {"reason": "Incorrect fact", "text": "Phillip Edward Van Lear", "type": 0, "start": 138}, {"reason": "Not checkable", "text": "is in color", "type": 1, "start": 172}, {"reason": "Incorrect fact", "text": "Castle Hill Productions", "type": 0, "start": 207}, {"reason": "Not checkable", "text": "English", "type": 1, "start": 251}, {"reason": "Not checkable", "text": "revolves around", "type": 1, "start": 263}, {"reason": "Misleading", "text": "Chicago", "type": 2, "start": 305}], "campaign_id": "quintd1-gpt-4", "batch_id": 50}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 51, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "male", "type": 0, "start": 23}, {"reason": "The fact in the text contradicts the data.", "text": "judge", "type": 0, "start": 28}, {"reason": "The fact in the text contradicts the data.", "text": "from", "type": 0, "start": 34}, {"reason": "The fact in the text contradicts the data.", "text": "Wanzleben-B\u00f6rde", "type": 0, "start": 63}, {"reason": "The fact in the text contradicts the data.", "text": "passed away", "type": 0, "start": 83}, {"reason": "The fact in the text contradicts the data.", "text": "in", "type": 0, "start": 95}], "campaign_id": "quintd1-gpt-4", "batch_id": 51}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 52, "annotations": [], "campaign_id": "quintd1-gpt-4", "batch_id": 52}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 53, "annotations": [{"reason": "The text mentions 'Spain' as a location, while the data specifies 'Ja\u00e9n, Spain'", "text": "Spain", "type": 0, "start": 48}, {"reason": "The text mentions 'Ja\u00e9n Province', while the data specifies 'Ja\u00e9n'", "text": "Ja\u00e9n Province", "type": 0, "start": 78}, {"reason": "The text incorrectly states that Diario Ja\u00e9n serves as a prominent source of news and information within its headquarters location, which is misleading.", "text": "serves as a prominent source of news and information within its headquarters location", "type": 2, "start": 140}], "campaign_id": "quintd1-gpt-4", "batch_id": 53}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 54, "annotations": [{"reason": "Composer information is missing from the text", "text": "Motociklu vasara", "type": 1, "start": 0}, {"reason": "Country of origin information is missing from the text", "text": "Motociklu vasara", "type": 1, "start": 0}, {"reason": "The text provides incorrect information about the language of the film", "text": "Russian", "type": 0, "start": 242}], "campaign_id": "quintd1-gpt-4", "batch_id": 54}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 55, "annotations": [{"reason": "Incorrect fact: The text states 'a citizen of the Polish-Lithuanian Commonwealth' while the data specifies 'country of citizenship: Polish\u2013Lithuanian Commonwealth'", "text": "citizen of the Polish-Lithuanian Commonwealth", "type": 0, "start": 157}, {"reason": "Other: The text is not grammatically incorrect but slightly repetitive", "text": "was a male individual", "type": 3, "start": 12}], "campaign_id": "quintd1-gpt-4", "batch_id": 55}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 56, "annotations": [{"reason": "Not checkable", "text": "Carlo Vittore Papardo", "type": 1, "start": 0}, {"reason": "Incorrect fact: The fact in the text contradicts the data", "text": "male", "type": 0, "start": 28}, {"reason": "Incorrect fact: The fact in the text contradicts the data", "text": "various", "type": 0, "start": 108}, {"reason": "Incorrect fact: The fact in the text contradicts the data", "text": "prominent", "type": 0, "start": 209}, {"reason": "Other", "text": "in the Catholic Church", "type": 3, "start": 226}], "campaign_id": "quintd1-gpt-4", "batch_id": 56}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 57, "annotations": [{"reason": "The text mentions 'based in Munich, Germany' but the data only mentions 'headquarters location: Munich'.", "text": "Munich, Germany,", "type": 0, "start": 76}, {"reason": "The text mentions 'location in Berlin' but the data only mentions 'location: Berlin'.", "text": "location in Berlin", "type": 0, "start": 100}, {"reason": "The text mentions 'organization focuses on the objective of Sustainable Development Goals' but the data mentions 'objective of project or action: Sustainable Development Goals', which is less specific.", "text": "objective of Sustainable Development Goals", "type": 0, "start": 152}, {"reason": "The text is using a less specific description compared to the data, which could be misleading as it may not fully capture the nature of the organization.", "text": "business incubator and nonprofit organization", "type": 2, "start": 21}], "campaign_id": "quintd1-gpt-4", "batch_id": 57}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 58, "annotations": [{"reason": "Incorrect fact: The fact in the text contradicts the data.", "text": "Wikimedia list article", "type": 0, "start": 122}], "campaign_id": "quintd1-gpt-4", "batch_id": 58}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 59, "annotations": [{"reason": "The text incorrectly states that the basic form of government was a confederation. The data specifies it as a confederation, contradicting the text", "text": "confederation", "type": 0, "start": 82}, {"reason": "The text incorrectly states that the capital was located in the continent of Asia. The data does not mention the location of the capital", "text": "Asia", "type": 1, "start": 150}, {"reason": "The text incorrectly states that the official language was used and spoken. The data only mentions the official language as Arabic", "text": "used and spoken", "type": 0, "start": 178}], "campaign_id": "quintd1-gpt-4", "batch_id": 59}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 60, "annotations": [{"reason": "Incorrect fact: The fact in the text contradicts the data.", "text": "color", "type": 0, "start": 246}, {"reason": "Other: The text is problematic for another reason, e.g. grammatically or stylistically incorrect, irrelevant, or repetitive.", "text": "The film is known for its captivating storyline and vibrant color scheme.", "type": 3, "start": 186}], "campaign_id": "quintd1-gpt-4", "batch_id": 60}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 61, "annotations": [{"reason": "The cast member 'Frank Marlowe' is missing from the text", "text": "Frank Marlowe", "type": 0, "start": 72}, {"reason": "The cast member 'Mischa Auer' is missing from the text", "text": "Mischa Auer", "type": 0, "start": 87}, {"reason": "The cast member 'Chrispin Martin' is missing from the text", "text": "Chrispin Martin", "type": 0, "start": 116}, {"reason": "The cast member 'Michael Visaroff' is missing from the text", "text": "Michael Visaroff", "type": 0, "start": 137}, {"reason": "The director of photography 'Lucien Andriot' is missing from the text", "text": "Lucien Andriot", "type": 0, "start": 248}, {"reason": "The producer 'Jesse Louis Lasky' is missing from the text", "text": "Jesse Louis Lasky", "type": 0, "start": 181}, {"reason": "The original language of film or TV show 'English' is missing from the text", "text": "English", "type": 0, "start": 309}, {"reason": "The screenwriter 'Wallace Smith' is missing from the text", "text": "Wallace Smith", "type": 0, "start": 233}], "campaign_id": "quintd1-gpt-4", "batch_id": 61}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 62, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "was characterized by its use of Amazigh languages", "type": 0, "start": 47}, {"reason": "Misleading: The fact in the text is misleading in the given context.", "text": "in the Iberian Peninsula", "type": 2, "start": 139}], "campaign_id": "quintd1-gpt-4", "batch_id": 62}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 63, "annotations": [{"reason": "Incorrect fact: The text states gender as female, but the data doesn't provide this information", "text": "female", "type": 0, "start": 20}, {"reason": "Incorrect fact: The text states the cause of death as due to pneumonia, but the data doesn't provide this information", "text": "pneumonia", "type": 0, "start": 247}, {"reason": "Incorrect fact: The text states the death as due to natural causes, but the data doesn't provide this information", "text": "natural causes", "type": 0, "start": 298}], "campaign_id": "quintd1-gpt-4", "batch_id": 63}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 64, "annotations": [{"reason": "The text states that Annesley John Garrett is a male human, which contradicts the data that states 'sex or gender: male' without mentioning 'human'.", "text": "male human", "type": 0, "start": 27}, {"reason": "The text mentions the military rank of 'colonel' without specifying whether it is 'of colonel'.", "text": "colonel", "type": 1, "start": 69}], "campaign_id": "quintd1-gpt-4", "batch_id": 64}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 65, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "FSK 12", "type": 0, "start": 141}, {"reason": "The fact in the text contradicts the data", "text": "color", "type": 0, "start": 168}, {"reason": "The fact in the text contradicts the data", "text": "German language", "type": 0, "start": 188}, {"reason": "The fact in the text contradicts the data", "text": "shot by the director of photography, Gernot Roll", "type": 0, "start": 212}], "campaign_id": "quintd1-gpt-4", "batch_id": 65}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 66, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "Carrozzeria Helvetia is an automobile manufacturer", "type": 0, "start": 0}, {"reason": "The fact in the text contradicts the data", "text": "Rozzano", "type": 0, "start": 60}, {"reason": "The fact in the text contradicts the data", "text": "automotive industry", "type": 0, "start": 97}, {"reason": "The fact in the text contradicts the data", "text": "automobiles", "type": 0, "start": 161}], "campaign_id": "quintd1-gpt-4", "batch_id": 66}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 67, "annotations": [{"reason": "The text mentions 'cast' instead of 'cast member'", "text": "includes", "type": 0, "start": 92}, {"reason": "The text mentions 'cast' instead of 'cast member'", "text": "includes", "type": 0, "start": 92}, {"reason": "The text mentiones 'cast' instead of 'cast member'", "text": "includes", "type": 0, "start": 92}, {"reason": "The text mentiones 'cast' instead of 'cast member'", "text": "includes", "type": 0, "start": 92}, {"reason": "The film is referred as 'Rich Relations' instead of 'film'", "text": "Rich Relations", "type": 0, "start": 0}], "campaign_id": "quintd1-gpt-4", "batch_id": 67}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 68, "annotations": [{"reason": "Not checkable", "text": "The Haunted Oak", "type": 1, "start": 0}, {"reason": "Not checkable", "text": "is considered a lost film", "type": 1, "start": 177}, {"reason": "Incorrect fact", "text": "in the public domain", "type": 0, "start": 214}, {"reason": "Misleading", "text": "now", "type": 2, "start": 210}, {"reason": "Incorrect fact", "text": "public viewing and distribution", "type": 0, "start": 260}], "campaign_id": "quintd1-gpt-4", "batch_id": 68}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 69, "annotations": [{"reason": "Not checkable", "text": "male", "type": 1, "start": 26}, {"reason": "Not checkable", "text": "the United States of America", "type": 1, "start": 58}, {"reason": "Incorrect fact", "text": "Wesleyan University", "type": 0, "start": 107}, {"reason": "Incorrect fact", "text": "The Pilgrim's Progress", "type": 0, "start": 163}, {"reason": "Not checkable", "text": "Methodist religion", "type": 1, "start": 219}], "campaign_id": "quintd1-gpt-4", "batch_id": 69}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 70, "annotations": [{"reason": "Incorrect fact: The genre is described as 'silent film' in the text, while it is specified as 'silent short film' in the data", "text": "silent film", "type": 0, "start": 198}, {"reason": "Misleading: The film is described as being available for 'public use' in the text, but its copyright status is 'public domain' in the data", "text": "public use", "type": 2, "start": 152}], "campaign_id": "quintd1-gpt-4", "batch_id": 70}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 71, "annotations": [{"reason": "The text does not specify that the cooperative is specializing in beekeeping", "text": "cooperative specializing in beekeeping", "type": 0, "start": 94}], "campaign_id": "quintd1-gpt-4", "batch_id": 71}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 72, "annotations": [{"reason": "The text mentions 'Ashot de Taron is a male human.' whereas the data does not include the occupation 'human'.", "text": "human", "type": 0, "start": 25}], "campaign_id": "quintd1-gpt-4", "batch_id": 72}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 73, "annotations": [{"reason": "The text mentions 'Oudh State' as a historical country, which contradicts the data.", "text": "historical country", "type": 0, "start": 17}, {"reason": "The text mentions 'Oudh State' as located, which is a not checkable fact based on the data.", "text": "located", "type": 1, "start": 76}], "campaign_id": "quintd1-gpt-4", "batch_id": 73}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 74, "annotations": [{"reason": "The fact in the text contradicts the data.", "text": "United States of Belgium", "type": 0, "start": 4}, {"reason": "The fact in the text contradicts the data.", "text": "Belgian", "type": 0, "start": 321}, {"reason": "The fact in the text contradicts the data.", "text": "predominant", "type": 0, "start": 179}, {"reason": "The fact in the text contradicts the data.", "text": "categorized as a", "type": 0, "start": 272}], "campaign_id": "quintd1-gpt-4", "batch_id": 74}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 75, "annotations": [{"reason": "The text mentions 'Kingston University' as a single employer, which contradicts the data that lists two employers", "text": "Kingston University", "type": 0, "start": 63}, {"reason": "The text doesn't provide information about Andrea's involvement in research activities with the Consiglio Nazionale delle Ricerche, which is listed in the data", "text": "Consiglio Nazionale delle Ricerche", "type": 1, "start": 87}], "campaign_id": "quintd1-gpt-4", "batch_id": 75}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 76, "annotations": [{"reason": "Incorrect fact: The fact in the text contradicts the data.", "text": "operating in the petroleum industry", "type": 0, "start": 46}], "campaign_id": "quintd1-gpt-4", "batch_id": 76}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 77, "annotations": [{"reason": "The fact contradicts the data", "text": "male", "type": 0, "start": 17}], "campaign_id": "quintd1-gpt-4", "batch_id": 77}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 78, "annotations": [{"reason": "The fact contradicts the data", "text": "Japan", "type": 0, "start": 57}, {"reason": "The fact contradicts the data", "text": "Wakayama Prefecture", "type": 0, "start": 84}, {"reason": "The fact contradicts the data", "text": "Nishimuro District", "type": 0, "start": 105}, {"reason": "The fact contradicts the data", "text": "Shirahama", "type": 0, "start": 129}, {"reason": "The fact contradicts the data", "text": "Kansai region", "type": 0, "start": 155}, {"reason": "The Japanese characters are not checkable in the data", "text": "\u70ad\u9178\u6c34\u7d20\u5869\u6cc9", "type": 1, "start": 192}, {"reason": "The text is redundant", "text": "carbonated hydrogen carbonate spring", "type": 3, "start": 214}, {"reason": "The text is misleading due to repetition", "text": "natural hot spring", "type": 2, "start": 413}, {"reason": "The text is redundant", "text": "natural hot spring water", "type": 3, "start": 413}], "campaign_id": "quintd1-gpt-4", "batch_id": 78}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 79, "annotations": [{"reason": "The text mentions a totalitarian regime, contradicting the data", "text": "totalitarian regime", "type": 0, "start": 121}, {"reason": "The text mentions the country's association with the Pahlavi dynasty, which is not explicitly supported by the data", "text": "Pahlavi dynasty", "type": 2, "start": 257}], "campaign_id": "quintd1-gpt-4", "batch_id": 79}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 80, "annotations": [{"reason": "Incorrect fact: The fact in the text contradicts the data.", "text": "business", "type": 0, "start": 35}], "campaign_id": "quintd1-gpt-4", "batch_id": 80}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 81, "annotations": [{"reason": "None of the given data mentions that the company 'Schw\u00f6rer Haus' is specifically called 'German'", "text": "German", "type": 0, "start": 19}, {"reason": "The legal form as mentioned in the text, 'Kommanditgesellschaft', matches the data provided", "text": "Kommanditgesellschaft", "type": 1, "start": 132}], "campaign_id": "quintd1-gpt-4", "batch_id": 81}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 82, "annotations": [{"reason": "Incorrect fact: The text mentions 'Polish' as the official language, but the data mentions 'official language: Polish'", "text": "Polish", "type": 0, "start": 155}, {"reason": "Incorrect fact: The text mentions 'played a significant role in the region's history', but the data doesn't mention any role played", "text": "played a significant role in the region's history", "type": 0, "start": 361}], "campaign_id": "quintd1-gpt-4", "batch_id": 82}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 83, "annotations": [{"text": "silent short film", "reason": "The genre in the text contradicts the data", "type": 0, "start": 21}, {"text": "directed by Igor Gostev and Joseph A. Golden", "reason": "The text contains a list of directors but the data doesn't support it", "type": 0, "start": 60}, {"text": "detective fiction", "reason": "The genre in the text contradicts the data", "type": 0, "start": 194}, {"text": "written by Joseph A. Golden", "reason": "The text contains the name of the writer but the data doesn't mention it", "type": 0, "start": 220}], "campaign_id": "quintd1-gpt-4", "batch_id": 83}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 84, "annotations": [{"reason": "Not checkable", "text": "Garsas", "type": 1, "start": 0}, {"reason": "Not checkable", "text": "(\u0160enandoa)", "type": 1, "start": 7}], "campaign_id": "quintd1-gpt-4", "batch_id": 84}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 85, "annotations": [{"reason": "The text mentions 'factory' whereas the data doesn't contain such information", "text": "factory", "type": 0, "start": 51}, {"reason": "The text mentions 'business' whereas the data doesn't contain such information", "text": "business", "type": 0, "start": 38}], "campaign_id": "quintd1-gpt-4", "batch_id": 85}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 86, "annotations": [{"reason": "The text mentions 'Swisscom IT Services Finance' as a business, but it does not match the data that states 'instance of: business'", "text": "Swisscom IT Services Finance is a business", "type": 0, "start": 0}, {"reason": "The location in the text 'Z\u00fcrich' does not match the data that states 'headquarters location: Z\u00fcrich'", "text": "headquartered in Z\u00fcrich", "type": 0, "start": 43}, {"reason": "The legal form 'Aktiengesellschaft' mentioned in the text does not match the data that states 'legal form: Aktiengesellschaft'", "text": "as an Aktiengesellschaft", "type": 0, "start": 80}], "campaign_id": "quintd1-gpt-4", "batch_id": 86}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 87, "annotations": [{"reason": "Incorrect fact: The text states that the sultanate is no longer in existence, while the data does not provide this information.", "text": "no longer in existence", "type": 0, "start": 155}], "campaign_id": "quintd1-gpt-4", "batch_id": 87}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 88, "annotations": [{"reason": "Incorrect fact: The genre in the text contradicts the data", "text": "documentary", "type": 0, "start": 33}, {"reason": "The word 'classified as' is misleading because it is not explicit in the data", "text": "classified as", "type": 2, "start": 124}], "campaign_id": "quintd1-gpt-4", "batch_id": 88}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 89, "annotations": [{"reason": "Incorrect fact: The fact in the text contradicts the data.", "text": "broadsheet", "type": 0, "start": 33}], "campaign_id": "quintd1-gpt-4", "batch_id": 89}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 90, "annotations": [{"reason": "The text mentions 'female' while the data specifies 'sex or gender'", "text": "female", "type": 0, "start": 28}], "campaign_id": "quintd1-gpt-4", "batch_id": 90}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 91, "annotations": [{"reason": "The text mentions 'Bloud & Gay' as a publishing company, but in the data, it is mentioned as a publisher.", "text": "Bloud & Gay is a publishing company", "type": 0, "start": 0}, {"reason": "The text mentions 'Edmond Bloud' and 'Francisque Gay' as directors/managers, but in the data, they are mentioned as director/manager.", "text": "Edmond Bloud and Francisque Gay serving as directors/managers", "type": 0, "start": 58}], "campaign_id": "quintd1-gpt-4", "batch_id": 91}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 92, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "Sri Ksetra Kingdom", "type": 0, "start": 0}, {"reason": "The fact in the text contradicts the data", "text": "World Heritage Site", "type": 0, "start": 112}, {"reason": "The fact in the text contradicts the data", "text": "Pyu Ancient Cities", "type": 0, "start": 156}], "campaign_id": "quintd1-gpt-4", "batch_id": 92}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 93, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "female", "type": 0, "start": 29}], "campaign_id": "quintd1-gpt-4", "batch_id": 93}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 94, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "male", "type": 0, "start": 22}, {"reason": "The fact in the text contradicts the data", "text": "Seneschal of Gascony", "type": 0, "start": 78}, {"reason": "The fact in the text contradicts the data", "text": "named Antonio", "type": 0, "start": 133}, {"reason": "The fact in the text contradicts the data", "text": "human being", "type": 0, "start": 121}], "campaign_id": "quintd1-gpt-4", "batch_id": 94}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 95, "annotations": [{"reason": "Incorrect fact: The text mentions 'male', but the data does not include this information.", "text": "male", "type": 0, "start": 18}, {"reason": "Not checkable: The text mentions 'known for playing as a hooker', which is not directly verifiable with the available data.", "text": "known for playing as a hooker", "type": 1, "start": 78}, {"reason": "Not checkable: The text mentions 'has been a member', which is not directly verifiable with the available data.", "text": "has been a member", "type": 1, "start": 112}, {"reason": "Not checkable: The text mentions 'as well as', which is not directly verifiable with the available data.", "text": "as well as", "type": 1, "start": 173}, {"reason": "Not checkable: The text mentions 'Australia A national rugby union team', which is not directly verifiable with the available data.", "text": "Australia A national rugby union team", "type": 1, "start": 188}], "campaign_id": "quintd1-gpt-4", "batch_id": 95}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 96, "annotations": [{"reason": "The fact in the text contradicts the data", "text": "headquartered in", "type": 0, "start": 29}], "campaign_id": "quintd1-gpt-4", "batch_id": 96}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 97, "annotations": [{"reason": "The movie is referred to as a film, not by its full title", "text": "Legally Blonde", "type": 0, "start": 0}, {"reason": "The rating is mentioned, but the source is not the same as in the data", "text": "Category II", "type": 0, "start": 34}, {"reason": "The story is referred to as a movie", "text": "The movie is based on the story of Legally Blonde", "type": 0, "start": 60}], "campaign_id": "quintd1-gpt-4", "batch_id": 97}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 98, "annotations": [{"reason": "Incorrect fact: The fact in the text contradicts the data.", "text": "French Cameroons", "type": 0, "start": 0}, {"reason": "Incorrect fact: The fact in the text contradicts the data.", "text": "French Cameroons", "type": 0, "start": 175}, {"reason": "Other: The text is problematic for another reason, e.g. grammatically or stylistically incorrect, irrelevant, or repetitive.", "text": "French Cameroons", "type": 3, "start": 262}], "campaign_id": "quintd1-gpt-4", "batch_id": 98}
{"annotator_id": "gpt-4", "dataset": "quintd1-wikidata", "setup": {"id": "gpt-35", "model": "gpt-3.5"}, "split": "test", "example_idx": 99, "annotations": [{"reason": "The text mentions 'Margarita Sol\u00e1' as director, while this information is missing from the data", "text": "directed by Margarita Sol\u00e1", "type": 0, "start": 69}, {"reason": "The text mentions 'The original language of the film is Spanish', while this information is missing from the data", "text": "The original language of the film is Spanish.", "type": 0, "start": 183}], "campaign_id": "quintd1-gpt-4", "batch_id": 99}
